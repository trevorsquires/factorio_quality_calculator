\documentclass[11pt]{article}

% --------------------------------------------------
% Page layout
% --------------------------------------------------
\usepackage[margin=1in]{geometry}

% --------------------------------------------------
% Mathematics
% --------------------------------------------------
\usepackage{amsmath, amssymb, amsthm}
\usepackage{mathtools}

% --------------------------------------------------
% Fonts and typography
% --------------------------------------------------
\usepackage[T1]{fontenc}
\usepackage{lmodern}

% --------------------------------------------------
% Figures and tables (if needed later)
% --------------------------------------------------
\usepackage{graphicx}
\usepackage{booktabs}

% --------------------------------------------------
% Hyperlinks (minimal, non-intrusive)
% --------------------------------------------------
\usepackage[hidelinks]{hyperref}

% --------------------------------------------------
% Theorem environments
% --------------------------------------------------
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}

% --------------------------------------------------
% Custom commands
% --------------------------------------------------
\newcommand{\E}{\mathbb{E}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\rhoL}{\rho(L)}

% --------------------------------------------------
% Document metadata
% --------------------------------------------------
\title{A Linear–Markov Model for Quality Upcycling in Factorio}
\author{Trevor Squires}



\begin{document}

\maketitle

\section{Introduction}
The date is 12-15-2025.  I've just completed a 27 hour 'speedrun' of a game called Factorio bringing my total hours played to near 650 - 200 of which occuring in the past month.
Having committed such a large percentage of recent my brain activity towards this game, I feel it is fitting to share some of those analytical inspirations that make the game so interesting for me.
In this document, I will advance the community's resources by providing simple to understand relations that govern one of the game's more analytically challenging mechanics.

For those of you who aren't Factorio mega-fans, Factorio is a popular factory building game that is ripe with mathematical potential.
The goal is to produce different materials, progress through a technology tree, and ultimately build an ever-growing factory of material automation.
In my opinion, it is a must-have for engineers (particularly those in the software space).
Much of the core principles of Factorio are shared with engineering such as: abstraction, system design, modularity, latency, debugging, and dozens of others.
The main draw for me in particular is its system design aspects which themselves are often represented by mathematical systems.
I've done countless (and often unnecessarily complicated) analyses of Factorio systems to optimize the tiniest amount of efficiency.
And while it's true that the majority of that work is largely overkill, it often comes in the form of neat applications of deeper mathematical theory that you won't get elsewhere.
For our discussion today, we will focus on one such area in particular that I haven't had a chance to do (or write about) from other games: a Markovian-like dynamical system defined by Factorio's upcycling routines.

\section{Quality Mechanics in Factorio}
\subsection*{The Desire for Quality}
To understand the problems faced in the upcycling routine, we must first understand the quality mechanic in Factorio.
As mentioned previously, Factorio is a game of building items.
In a recent update, the developers added different quality versions of items.
These higher quality items are better than the base version in different ways, but usually represent a significant - even necessary - improvement over the base item.
For example, for items that have a "speed" mechanic, i.e. they do something in a certain amount of time, a top tier quality item will do this thing 2.5 times faster than the base version.
This means if you were to utilize these higher quality items instead of regular ones, your base would be significantly smaller.
Obtaining quality versions of every item is a challenge every large-factory-building Factorio veteran will tackle at some point.

\subsection*{Quality Upgrading}
There are two ways of obtaining a quality version of an item.
The first is simple: use quality ingredients whenever you craft the item.
However simple, this is not usually the way most quality items are obtained.
After all, we've only reduced the problem by one degree: we still have to get the quality ingredients.
The more common (and complicated) way is to craft said item with a certain "quality percentage" for the craft.
This quality percentage can be affected through the use of modules, but for now let's just assume that we don't have any control over this value that we call $q$.
If an item of base quality is crafted with a quality percentage of $q$, then the likelihood that the output is $1$ quality level higher is $\frac{9q}{10}$, 2 levels higher is $\frac{9q}{100}$ and in general for $k$ levels higher it is $\frac{9q}{10^k}$.
Let's see this in an example using 5 quality levels that exist in the game:
\begin{enumerate}
    \item Normal
    \item Uncommon
    \item Rare
    \item Epic
    \item Legendary
\end{enumerate}
If I craft an item using normal ingredient with $q=30\%$ quality, then I will have a $1-q=70\%$ chance for the resulting item to be of normal quality, but a $27\%$ chance for the item to be uncommon, $2.7\%$ chance for rare, and so forth.
The sum of the probabilities must equal $1$, so the remaining tail of the probability distribution gets tucked into the legendary percentage, but it is typically trivial for analysis sake.
Had I crafted with rare materials instead, the probabilities remain the same, except with every quality level being raised by two stages.

\subsection*{Quality Upcycling}
As described above, one can obtain quality goods from non-quality ones simply by crafting with an innate quality percentage.
However, obtaining quality goods in this way can be quite obnoxious for a few reasons:
\begin{enumerate}
    \item The quality percentage cannot go very high and is often a small number, leading to many crafts necessary to obtain a high quality item
    \item All the failed attempts of quality crafting essentially go to waste.  For expensive items, it is not easy to craft and waste so many of them
\end{enumerate}
Thankfully, Factorio introduced a way to alleviate both of these concerns: recycling.  Recycling is a mechanic that allows you to recycling a crafted item for $25\%$ of the ingredients.
So all of these 'failed upgrades' during the quality process can now be recycled and attempted again, though at a reduced efficiency rate.
However, there is an additional benefit to recycling - items can be recycled with an innate quality percentage just like assembling/crafting.
In this regard, the recycled ingredients of an item with quality recycling follow the same $1-q$ probabilities described above, though they still suffer the $75\%$ loss of materials.

These two mechanics together (assembling and recycling) can be combined in an iterative process usually referred to as upcycling.  The process looks like the following:
\begin{enumerate}
    \item Craft an item with a certain quality percentage with a target quality in mind
    \item If the result is not the desired quality, recycle it down to ingredients again using quality percentage
    \item If you have enough raw ingredients to craft a new item, craft said new item. If not, go back to step 1 and start again
\end{enumerate}
In this upcycling process, resources are fully utilized to obtain the desired quality without any waste.
The challenge, of course, is understanding how this upcycling system is going to behave.  Because of the tricky quality upgrading mechanics and the fact that there is are two steps in the iteration make it non-trivial to analyze.
Even worse, there are additional mechanics such as productivity that complicate the process.
Though there are simple cases, I hope to do a full analysis of the upcycling dynamics and provide relations to completely understand the long-term system behavior of the non-trivial upcycling loop.


\section{Modeling Components}
The purpose of this section is to define a minimal mathematical language that mirrors the mechanics of quality upcycling in Factorio, while remaining flexible enough to support analysis and optimization.
Let us index one iteration loop by a counter $t = 0,1,2,\dots$, where each iteration corresponds to one complete loop of assembly followed by recycling.
Quality is discretized into $n = 5$ ordered classes indexed by $i \in \{0,1,2,3,4\}$, with $i = 0$ representing base quality and $i = 4$ representing legendary quality.
Legendary items are an absorbing state and will later exit the loop so we don't put them back into a recycler (and lose some of the material).

\subsection*{Decomposition of a Loop}
Each loop consists of two conceptually distinct stages.

\begin{enumerate}
\item \emph{Assembly}: recyclable material is converted into the chosen item. Assembly may increase quality and applies a productivity bonus.
\item \emph{Recycling}: non-legendary items are recycled, returning a fraction of their material input and potentially increasing quality further.
\end{enumerate}
This breakdown of a loop into assembly and recycling will prove helpful later as we'll be able to make very strong claims about the operators of each sub-process.

\subsection*{State Variables}
Let $M_{i,t}$ denote the amount of recycled material of quality $i$ available at the beginning of iteration $t$ measured in item-equivalents.
For example, $M_{4,3}$ denotes the number of legendary quality item-equivalent ingredients at the beginning of iteration $3$.
Furthermore, let $C_{i,t}$ denote the expected number of items of quality $i$ produced after crafting the previous $M$ materials into items.
Importantly $M_{i,t} = C_{i,t}$ need not be true due to the productivity and quality percentage of crafting.
For brevity, we will often collect these quantities into vectors
\begin{equation*}
M_t = (M_{0,t}, M_{1,t}, M_{2,t}, M_{3,t}, M_{4,t})^\top,
\qquad
C_t = (C_{0,t}, C_{1,t}, C_{2,t}, C_{3,t}, C_{4,t})^\top.
\end{equation*}

\subsection*{Assembly and Recyling Operators}
Assembly quality behavior is encoded by a matrix $A \in \mathbb{R}^{5 \times 5}$, where $A_{ij}$ is the probability that material of quality $i$ produces a circuit of quality $j$ during assembly.
Recycling quality behavior is encoded by a matrix $R \in \mathbb{R}^{5 \times 5}$, defined analogously.
Separately, let us also define $p>0$ as the productivity applied during assembly.  That is, whenever an assembly of an item is completed, a total of $1+p$ quantities of that item are produced \textit{all of the same quality}.
Similarly, define $r \in (0,1)$ to be the fraction of materials returned by the recycler.  In Factorio, this is always $25\%$ and cannot be modified, but let us generalize it for the sake of completeness.
Regarding quality, define $q_a$ and $q_r$ to be the quality percentage during the assembly and recycling components of a single loop.
Lastly, using Factorio's quality mechanic upgrade structure, both $A$ and $R$ have an identical structure using their definitions of $q_a$ and $q_r$ respectively:
\begin{equation*}
R_{ij}
=
\begin{cases}
    0, & j<i\\
1 - q_r, & i=j, \\[6pt]
\dfrac{9 q_r}{10^{\Delta}}, & 1 \le j < 4, \\[10pt]
\dfrac{q_r}{10^{3-i}}, & j = 4
\end{cases}
\end{equation*}
where $\Delta = j-i$. $A_{ij}$ is defined similarly using $q_a$ in place of $q_r$.
Simply put, $A$ and $R$ represent the expected transformation that the upcycling system goes through when putting everything into an assembler/recycler, respectively.
These two matrices are linear operators that have a few nice properties.  They are:
\begin{itemize}
    \item upper triangular (no non-zero entries in the lower half of the matrix)
    \item row-stochastic (rows sum to 1)
\end{itemize}


\section{Derivation of Key Relations}
With the definitions presented in the previous section, we can start to derive relations by translating the Factorio mechanics into mathematics.

\subsection*{Recurrence Relations}
Note that by definition of a single iteration loop, we have the following equations regarding the number of materials pre- and post- recycling.
First, we have
\begin{equation*}
    C_t = p A^\top M_t
\end{equation*}
which effectively says that the distribution of quality items produced at step $t$ is the result of applying the linear operator $A$ to the materials present at the start of iteration $t$, scaled upward accounting for productivity.  Similarly, we also have
\begin{equation*}
    M_{t+1} = rR^{\top}\Pi C_t
\end{equation*}
meaning that the number of materials available at the beginning of loop $t+1$ is result of applying the linear operator $R$ to the number of items in iteration $t$, scaled downward accounting for recycling material loss.
The only difference here is the existence of the projection matrix $\Pi$ which represents the action of removing legendary items from circulation before recycling everything\footnote{Test yourself: what does $\Pi$ look like in matrix form?}.
Combining these two, we have the all-in-one relation
\begin{equation*}
    M_{t+1} = r(1+p) R^{\top}\Pi A^{\top}M_t = LM_t
\end{equation*}
with $L = r(1+p)R^\top \Pi A^\top$ representing the transformation of materials from one loop to the next. The definitions of $A, R$, and $L$ help us derive many properties of the upcycling system.

\subsection*{Mass Decay}
Since both $A$ and $R$ are row-stochastic, the total amount of material in circulation must necessarily decrease provided that $r(1+p) < 1$ since
\begin{align*}
    ||L||_1 &= ||r(1+p)R^{\top}\Pi A^{\top}||_1\\
    &= r(1+p)||R^{\top}\Pi A^{\top}||_1\\
    &\leq r(1+p)||R^{\top}||_1||\Pi||_1||A^{\top}||_1\\
    &\leq r(1+p)\\
    &< 1
\end{align*}
This derivation shows that the 1-norm of $L$ - and consequently its  spectral radius $\rho(L)$ - is less than $1$. This property is necessary for much of our remaining properties to hold.
In fact, one could argue for something slightly stronger by exploiting properties of $\Pi$, but specifically for Factorio there is no need to.
For somewhat obvious reasons, due to their inherent setting of $r=0.25$, the developers introduced a $300\%$ maximum productivity. This alone guarantees our spectral radius is no larger than $1$.
For our non-technical purposes, that simply means given a certain number of inputs, a finite number of legendary items will be produced if we let our system run for an indefinite amount of time.

\subsection*{Legendary Production}
One of the more fundamental questions for upcycling is: given a certain amount of the initial item, how many legendary versions of this item will I obtain after I let the upcycling process fully run to termination?
To answer this question, first note that we can slightly generalize the question into: over the entire course of the upcycling process, how much of each item quality will I produce?
This can be written as
\begin{equation*}
    C_{total} = \sum_{t=0}^{\infty} C_t
\end{equation*}
but since the spectral radius of $L$ satisfies $\rho(L)<1$, we can rewrite this Neumann series as
\begin{align*}
    \sum_{t=0}^{\infty} C_t &= \sum_{t=0}^{\infty} (1+p) A^{\top}L^t M_0\\
    &= (1+p)A^{\top}\sum_{t=0}^{\infty}L^t M_0\\
    &= (1+p)A^{\top}(I-L)^{-1}M_0
\end{align*}
where $M_0$ denotes the vector of initial items we begin the upcycling process with.
The number of legendary items produced during this process (which is equivalent to the number of legendary items we are left with at the end of the process) is given by the last component of the vector $C_{total}$.
In other words, by setting $M_0 = e_0$, $e_4^\top (1+p) A^{\top}(I-L)^{-1}e_0$ denotes the amount of legendary material we obtain from upcycling one item of regular quality.  Here, $e_k$ is used to denote the identify vector of all zeros with a singular $1$ in the $k$-th component.

\subsection*{Steady State Behavior}
Most applications of upcycling don't have fixed start/stop points.  Rather, a steady production of $s$ normal quality items are produced "per iteration" and added to the upcycling system.
We've seen in previous sections that since $r(1+p)<1$, the number of items in circulation should strictly decrease, but if new materials are added each iteration, then eventually the system will reach some steady state behavior where the number of items being recycled out is equal to the number of items being added per loop.
This steady state is of interest because it defines the ordinary operating state of the upcycler.
One question we can ask ourselves about the steady state dynamics is how many items are in circulation in steady state?
This is quite an easy answer using our recurrence relation
\begin{equation*}
    M_{t+1} = LM_{t} + S
\end{equation*}
accounting for the addition of the vector of $S$ (usually $c\cdot e_0$ items in each loop for some constant $c$) to the system on each iteration.
The steady state solution $M^*$ must satisfy
\begin{equation*}
    M^* = LM^* + S
\end{equation*}
or in other words
\begin{equation*}
    M^* = (I-L)^{-1}S
\end{equation*}
Using this vector\footnote{Ask yourself why this solution looks so similar to the previous one}, one can determine approximately how large a factory needs to be to support an upcycling system capable of producing a fixed number of legendary items per loop.

\section{Results Summary and Examples}
If the last section was a bit math-heavy, this section should be a reprieve as it is primarily focused on using the results above.
In fact, the above results are so simply stated that they can be employed in a short ~30 line script.
For the sake of an example, let us choose the following parameters
\begin{itemize}
    \item $r=0.25$
    \item $p=1+0.5$
    \item $q_r=20\%$
    \item $q_a=25\%$
\end{itemize}
For the Factorio fans out there, these parameters are derived from assembling red circuits using EM plants with legendary quality 3 modules in every step of the process.
Let us assume that we begin with 32 red circuit-equivalent materials to start out with - meaning we could craft a red circuit 32 times using these materials.
Let us also assume that during each loop of our upcycler system, we add 32 more red circuit-equivalent materials to keep the process healthy.
By constructing the associated matrices and relevant parameters, we can quite quickly computed that
\begin{enumerate}
    \item After 1 full iteration of assembly + recycling, we are left with $[7.2, 3.78, 0.864, 0.135, 0.018]$ red circuit-equivalents of normal, uncommon, rare, epic, and legendary quality, respectively (before adding our additional 32)
    \item If we let our upcycling run for an indefinite amount of time without adding any additional inputs, the original $32$ materials produce roughly $0.65$ legendary circuits.  Meaning we need to produce about 50 normal quality red circuits to convert it into one legendary quality circuit.
    \item Similarly, if we continuously supply our system with 32 circuit-equivalents each iteration, our steady state system produces roughly $0.65$ legendary circuits per loop.  Additionally, there will be $[46.45, 21.01, 6.21, 2.07, 0.65]$ circuits of each respective quality in circulation. This helps designing the necessary size of the upcycler.
\end{enumerate}


\section{Choosing Productivity vs.\ Quality Modules in Assemblers}
One of the most practical decisions an engineer must make when designing an upcycling system is how to allocate module slots in assemblers between productivity and quality. In Factorio, this choice typically appears as a tradeoff between an additional $25\%$ productivity or an additional $5\%$ quality per module. While this decision is often discussed heuristically in the community, the linear–Markov framework developed above allows us to reason about it in a more principled way.
At a high level, productivity and quality influence the upcycling system in fundamentally different manners. Productivity acts as a scalar multiplier on the total amount of material flowing through the system, whereas quality reshapes the transition dynamics governing how quickly material escapes the recycling loop and is converted into legendary output. Understanding this distinction is key to making informed decisions.

\subsection*{Productivity as Mass Amplification}
Recall that productivity enters the model through the scalar factor $(1+p)$ in the loop operator
\begin{equation*}
L = r(1+p) R^\top \Pi A^\top.
\end{equation*}
Increasing productivity uniformly scales the amount of material produced during assembly and, consequently, the amount of material presented to the recycler. In isolation, higher productivity appears desirable: more items are produced per unit of input.
However, this amplification is indiscriminate. Additional productivity increases not only the flow of high-quality items toward absorption, but also the circulation of low-quality items that will be recycled multiple times and partially lost at each pass. From the perspective of the loop operator, increasing productivity pushes the spectral radius $\rho(L)$ upward, lengthening the expected lifetime of material within the recycling loop and increasing cumulative recycling losses.
In short, productivity increases throughput, but it also increases exposure to loss.

\subsection*{Quality as Escape Acceleration}
Quality, by contrast, alters the structure of the transition matrices $A$ and $R$. Increasing quality shifts probability mass upward in quality space, increasing the likelihood that an item exits the loop early by reaching the legendary state. In terms of the linear system, higher quality decreases the expected number of iterations before absorption.
This effect is nonlinear. A modest increase in quality can significantly reduce the expected number of recycling passes, especially when starting from low or moderate quality levels. As a result, quality improvements tend to reduce total material loss even though they do not increase raw throughput.
From the perspective of $(I-L)^{-1}$, increasing quality reduces the total mass accumulated in the transient subsystem before absorption.

\subsection*{Interpreting the Tradeoff}
The tension between productivity and quality can therefore be summarized as follows:
\begin{itemize}
\item Productivity increases how much material enters the system each loop.
\item Quality decreases how long material remains in the system.
\end{itemize}
An effective upcycling system must balance these two effects. Excessive productivity without sufficient quality leads to large volumes of low-quality material circulating for many iterations, incurring repeated recycling losses. Excessive quality without sufficient productivity, on the other hand, produces clean but anemic throughput.
Within the mathematical model, this balance is reflected in the behavior of the fundamental matrix $(I-L)^{-1}$. Productivity increases the magnitude of $L$, while quality reshapes $L$ so that its mass is directed more quickly toward absorption.

\subsection*{Rules of Thumb}
Several practical heuristics emerge naturally from this analysis.
First, quality is most valuable when the expected number of recycling passes is large. Early in an upcycling chain, or when starting from base-quality inputs, increasing quality tends to pay for itself by sharply reducing downstream losses.
Second, productivity becomes more attractive once the system reliably upgrades items within one or two loops. When most material reaches epic or legendary quality quickly, additional productivity primarily scales useful output rather than waste.
Third, a useful mental model is to think in terms of expected loop count. If a typical item is recycled many times before reaching legendary quality, prioritize quality. If most items are upgraded rapidly, prioritize productivity.
Finally, base productivity matters. When assemblers already have substantial built-in productivity, the marginal benefit of additional productivity modules diminishes relative to quality modules. In such settings, allocating early module slots to quality often produces better long-run results.

\subsection*{A Broader Perspective}
While the canonical Factorio numbers of $25\%$ productivity versus $5\%$ quality motivate much of this discussion, the same reasoning applies more generally. Any change that increases throughput should be weighed against its effect on the lifetime of material within lossy subsystems. Conversely, any change that accelerates absorption reduces cumulative loss, even if it does not increase immediate output.
Seen through this lens, the choice between productivity and quality modules is not merely a numerical comparison of percentages, but a question of system dynamics. The optimal choice depends less on local gains and more on how quickly the system converts raw inputs into terminal output.

\subsection*{Model-Based Comparison and Optimal Module Allocation}
The discussion above can be made precise within the linear framework already developed. In particular, the choice between productivity and quality modules can be posed as an optimization problem over the expected legendary yield obtained from a single injection of input material.
Suppose an assembler has a fixed number of module slots, say $M=5$. Let $m_p$ denote the number of productivity modules and $m_q = M - m_p$ the number of quality modules installed. We assume that productivity modules increase additive productivity by a fixed increment $\Delta_p$ per module, while quality modules increase assembly quality by a fixed increment $\Delta_q$ per module. Let $p_0$ denote the assembler’s base additive productivity. Then the effective parameters entering the model are
\begin{equation*}
p = p_0 + m_p \Delta_p,
\qquad
q_a = m_q \Delta_q,
\end{equation*}
with $q_r$ and $r$ held fixed by the recycler configuration.

For a one-time injection of material represented by a vector $S$, the total expected number of legendary items produced over the entire lifetime of the system was shown earlier to be
\begin{equation*}
e_4^\top (1+p)\,A^\top (I-L)^{-1} S,
\end{equation*}
where
\begin{equation*}
L = r(1+p)\,R^\top \Pi A^\top.
\end{equation*}
Normalizing by the total amount of injected material, we define the expected legendary yield per unit input as
\begin{equation*}
\eta(p,q_a;S)
=
\frac{e_4^\top (1+p)\,A^\top (I-L)^{-1} S}{\mathbf{1}^\top S}.
\end{equation*}
In the common case where one unit of base-quality material is injected, $S=e_0$, this quantity has a particularly direct interpretation: it is the expected number of legendary items ultimately produced per base item-equivalent consumed.
This scalar objective provides a principled way to compare module allocations. For each integer choice $m_p \in \{0,1,\dots,M\}$, one constructs the corresponding matrices $A$ and $L$ using $q_a = (M-m_p)\Delta_q$ and $p = p_0 + m_p\Delta_p$, evaluates $\eta$, and selects the maximizing configuration. Because the feasible set is small and discrete, the optimum can be found by straightforward enumeration.
Beyond identifying a single optimum, this formulation also clarifies the local tradeoff between productivity and quality. Consider replacing one productivity module with one quality module, holding all else fixed. The sign of the discrete difference
\begin{equation*}
\eta(p-\Delta_p, q_a+\Delta_q; S) - \eta(p,q_a; S)
\end{equation*}
determines whether quality or productivity is locally preferable at that operating point. This comparison captures, in a single quantity, both the throughput benefits of productivity and the loss-reduction benefits of quality.
Viewed this way, the common intuition discussed earlier can be restated more sharply. Quality modules tend to dominate when material is expected to circulate through many recycling loops before reaching legendary quality, since increasing $q_a$ substantially reduces the expected lifetime of material in the lossy subsystem. Productivity modules become more attractive once most material upgrades quickly, at which point additional throughput translates more directly into legendary output. The model provides a quantitative boundary between these regimes and allows the optimal balance to be computed rather than guessed.






















\end{document}